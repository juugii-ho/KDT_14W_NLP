{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from konlpy.tag import Okt\n",
    "from kiwipiepy import Kiwi\n",
    "from kiwipiepy.utils import Stopwords\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def funcDF_info(df, columns=None):\n",
    "\n",
    "    print(f'DF.info :\\n{df.info()}\\n\\n')\n",
    "    print(f'DF.describe :\\n{df.describe()}\\n\\n')\n",
    "    print(f'DF 결측치 파악 :\\n{df.isnull().sum()}\\n\\n')\n",
    "\n",
    "def funcDF_heatmap1(df):\n",
    "    sns.heatmap(df)\n",
    "\n",
    "def funcDF_heatmap2(df):\n",
    "    sns.heatmap(df.corr())\n",
    "\n",
    "def funcDF_pairplot(df):\n",
    "    sns.pairplot(df)\n",
    "\n",
    "def funcDF_boxplot(df, columns=None):\n",
    "    # 이상치 박스플롯\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(columns), figsize=(15, 5))\n",
    "    for i, column in enumerate(columns):\n",
    "        sns.boxplot(x=df[column], ax=axes[i])\n",
    "        axes[i].set_title(column)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    for column in columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df.loc[(df[column] < lower_bound) | (df[column] > upper_bound), column] = np.nan\n",
    "        print(f'{column}컬럼] Q1 : {Q1:.3f}, Q3 : {Q3:.3f}, IQR : {IQR:.3f}, 사분위범위 : {lower_bound:.3f} ~ {upper_bound:.3f}')\n",
    "\n",
    "\n",
    "def funcDF_histogram(df):\n",
    "    num_columns = df.shape[1]\n",
    "    num_rows = int(num_columns ** 0.5)\n",
    "    num_cols = (num_columns // num_rows) + (1 if num_columns % num_rows != 0 else 0)\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(10,6))\n",
    "    for i, column in enumerate(df.columns):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        sns.histplot(df[column], ax=axes[row, col], kde=True)\n",
    "        axes[row, col].set_title(column)\n",
    "\n",
    "    for i in range(num_columns, num_rows * num_cols):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        fig.delaxes(axes[row, col])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def funcDF_visualize(df, columns=None):\n",
    "    funcDF_histogram(df)\n",
    "    funcDF_heatmap1(df)\n",
    "    funcDF_heatmap2(df)\n",
    "    funcDF_pairplot(df)\n",
    "    funcDF_boxplot(df, columns=None)\n",
    "\n",
    "def funcDF_logAPPLY(df, columns=None):\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    for column in columns:\n",
    "        df[column] = np.log1p(df[column])\n",
    "    print('Log apply')\n",
    "    return df\n",
    "\n",
    "\n",
    "def funcNLP_Eng_tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    print('retrun : 토큰')\n",
    "    return tokens\n",
    "\n",
    "def funcNLP_Eng_tokenize_sentences(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    print('retrun : 문장')\n",
    "    return sentences\n",
    "\n",
    "def funcNLP_Eng_remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    print('retrun : 토큰')\n",
    "    return filtered_tokens\n",
    "\n",
    "def funcNLP_Eng_stem_tokens(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    print('retrun : 어간')\n",
    "    return stemmed_tokens\n",
    "\n",
    "def funcNLP_Eng_preprocess_text(text):\n",
    "    tokens = funcNLP_Eng_tokenize_text(text)\n",
    "    filtered_tokens = funcNLP_Eng_tokenize_sentences(tokens)\n",
    "    stemmed_tokens = funcNLP_remove_Eng_stopwords(filtered_tokens)\n",
    "    print('retrun : 텍스트 - 토큰 - 어간')\n",
    "    return stemmed_tokens\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def funcNLP_okt_tokenize(text):\n",
    "    tokens = okt.morphs(text)\n",
    "    return tokens\n",
    "\n",
    "def funcNLP_okt_pos_tagging(text):\n",
    "    pos_tagged = okt.pos(text)\n",
    "    return pos_tagged\n",
    "\n",
    "def funcNLP_okt_noun_extractor(text):\n",
    "    nouns = okt.nouns(text)\n",
    "    return nouns\n",
    "\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def funcNLP_kiwi_tokenize(text):\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def funcNLP_kiwi_pos_tagging(text):\n",
    "    pos_tagged = kiwi.analyze(text)\n",
    "    return pos_tagged\n",
    "\n",
    "def funcNLP_kiwi_noun_extractor(text):\n",
    "    nouns = [word.value for word in kiwi.analyze(text) if word.tag == 'NNG' or word.tag == 'NNP']\n",
    "    return nouns\n",
    "\n",
    "def funcNLP_kiwi_stopword(text):\n",
    "    stopwords = Stopwords()\n",
    "    stopword = stopwords.filter(kiwi.tokenize(text))\n",
    "    print('return : 불용어 필터 적용')\n",
    "    return stopword\n",
    "\n",
    "def funcNLP_punctuation(df,column):\n",
    "    punctuation = string.punctuation\n",
    "    df.column.replace(r'[{}]'.format(string.punctuation), '', regex=True, inplace=True)\n",
    "    hanguel_pattern = \"[^ㄱ-ㅎㅏ-ㅣ가-힣]\"\n",
    "    df.column = df.column.str.replace(hanguel_pattern, '', regex=True)\n",
    "    print('return : \"[^ㄱ-ㅎㅏ-ㅣ가-힣]\"정규화')\n",
    "    return df\n",
    "\n",
    "def funcNLP_isull_sum(df,column):\n",
    "    print(df.column.isnull().sum())\n",
    "\n",
    "def funcNLP_otk_stopword(stopwords_path, vocab):\n",
    "    with open(stopwords_path, encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "    stopwords = [word.strip() for word in stopwords]\n",
    "    for sword in stopwords:\n",
    "        if sword in vocab.keys():\n",
    "            vocab.pop(sword)\n",
    "    print('return : vocab')\n",
    "    return vocab\n",
    "\n",
    "def funcNLP_otk_vocab(df, vocab):\n",
    "    for idx in range(df.shape[0]):\n",
    "        result = okt.morphs(df.iloc[idx][0])\n",
    "        for word in result:\n",
    "            if len(word) >=2:\n",
    "                if vocab.get(word) != None:\n",
    "                    vocab[word] +=1\n",
    "                else:\n",
    "                    vocab[word] =1\n",
    "    sorted_vocab = sorted(vocab.items(), key= lambda x:x[1], reverse=True)\n",
    "    print('return : sorted_vocab')\n",
    "    return sorted_vocab\n",
    "\n",
    "def funcNLP_otk_vocab2(vocab,n):\n",
    "    vocab2 ={}\n",
    "    for k, v in vocab.items():\n",
    "        if v>n:\n",
    "            vocab2[k] = v\n",
    "    print('return : vocab2 - vocab 중 n개 이상 등장')\n",
    "    return vocab2\n",
    "\n",
    "def funcNLP_vocab2_visualize(vocab2, n):\n",
    "    sorted_vocab2 = sorted(vocab2.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    keys = [k for k, v in sorted_vocab2]\n",
    "    values = [v for k, v in sorted_vocab2]\n",
    "    print('vocab2 중 상위 n개 시각화')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(keys[:n], values[:n])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel('Keys')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('vocab2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,2,3,4],[1,2,3,4],[10,20,30,40]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kiwipie'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkiwipie\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordNet\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkiwi_semantic_analysis\u001b[39m(text):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"KiWi와 WordNet을 사용하여 의미 분석을 수행합니다.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kiwipie'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
